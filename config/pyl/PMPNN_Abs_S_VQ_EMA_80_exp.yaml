defaults:
 - PMPNN_Abs_S_Latent_FT_exp
 - override lm/latent_model: VQ_EMA_80

experiment:
  name: PMPNN_Abs_S_VQ_EMA_80_FT

lm:
  save_name: ${experiment.name}
  num_classes: 81
  model:
    name: PMPNN_Struct_Latent_Diff
    absorbing: True
    num_letters: ${lm.num_classes}
    vocab: ${lm.num_classes}
    num_classes: ${lm.num_classes}
    embedding_cfg:
      max_len: ${dm.max_protein_length}
      T: ${lm.num_timesteps}
      input_size: ${lm.num_classes} # relevant for codebook size.
      pos_embed_size: 64
      output_embed_size: ${lm.model.hidden_dim}